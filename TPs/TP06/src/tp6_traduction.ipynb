{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87a_cZOt3I8q"
      },
      "source": [
        "<center>\n",
        "<h1>Advanced Machine Learning and Deep Learning (Master DAC)</h1>\n",
        "<h2>TP 06 : Réseaux récurrents : Séquence à séquence (seq2seq)</h2>\n",
        "\n",
        "<hr>\n",
        "<strong>Ben Kabongo</strong>, M2 MVA <br>\n",
        "ben.kabongo_buzangu@ens-paris-saclay.fr <br>\n",
        "<i>Novembre 2023</i>\n",
        "<hr>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "69MsQuAM3I8s"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "import torch\n",
        "import unicodedata\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tckiG8OF3I8u"
      },
      "outputs": [],
      "source": [
        "def normalize(s):\n",
        "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
        "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
        "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jHg9Xpjq3I8u"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    PAD = 0\n",
        "    EOS = 1\n",
        "    SOS = 2\n",
        "    OOVID = 3\n",
        "\n",
        "    def __init__(self, oov: bool):\n",
        "        self.oov = oov\n",
        "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]\n",
        "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}\n",
        "        if oov:\n",
        "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
        "            self.id2word.append(\"__OOV__\")\n",
        "\n",
        "    def __getitem__(self, word: str):\n",
        "        if self.oov:\n",
        "            return self.word2id.get(word, Vocabulary.OOVID)\n",
        "        return self.word2id[word]\n",
        "\n",
        "    def get(self, word: str, adding=True):\n",
        "        try:\n",
        "            return self.word2id[word]\n",
        "        except KeyError:\n",
        "            if adding:\n",
        "                wordid = len(self.id2word)\n",
        "                self.word2id[word] = wordid\n",
        "                self.id2word.append(word)\n",
        "                return wordid\n",
        "            if self.oov:\n",
        "                return Vocabulary.OOVID\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.id2word)\n",
        "\n",
        "    def getword(self, idx: int):\n",
        "        if idx < len(self):\n",
        "            return self.id2word[idx]\n",
        "        return None\n",
        "\n",
        "    def getwords(self, idx: List[int]):\n",
        "        return [self.getword(i) for i in idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FD0ExweZ3I8v"
      },
      "outputs": [],
      "source": [
        "class TradDataset():\n",
        "    def __init__(self, data, vocOrig, vocDest, adding=True, max_len=10):\n",
        "        self.sentences = []\n",
        "        for s in tqdm(data.split(\"\\n\")):\n",
        "            if len(s)<1:continue\n",
        "            orig, dest=map(normalize,s.split(\"\\t\")[:2])\n",
        "            if len(orig) > max_len: continue\n",
        "            self.sentences.append((\n",
        "                torch.tensor(\n",
        "                    [vocOrig.get(o) for o in orig.split(\" \")] +\n",
        "                    [Vocabulary.EOS]\n",
        "                ),\n",
        "                torch.tensor(\n",
        "                    [vocDest.get(o) for o in dest.split(\" \")] +\n",
        "                    [Vocabulary.EOS]\n",
        "                )\n",
        "            ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.sentences[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m9OyK0Sh3I8v"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    orig, dest = zip(*batch)\n",
        "    o_len = torch.tensor([len(o) for o in orig])\n",
        "    d_len = torch.tensor([len(d) for d in dest])\n",
        "    return pad_sequence(orig),o_len,pad_sequence(dest),d_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rQxvpMvY3I8w"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_tokens, embedding_dim, hidden_size, padding_idx=0, num_layers=1, dropout=0,\n",
        "                device=torch.device(\"cpu\")):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(n_tokens, embedding_dim, padding_idx).to(device)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True).to(device)\n",
        "\n",
        "    def forward(self, X):\n",
        "        embedded = self.embedding(X)\n",
        "        _, h_n = self.rnn(embedded)\n",
        "        return h_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TYGsulKl3I8w"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_tokens, embedding_dim, hidden_size, padding_idx=0, num_layers=1, dropout=0,\n",
        "                sos_idx=Vocabulary.SOS, eos_idx=Vocabulary.EOS, device=torch.device(\"cpu\")):\n",
        "        super().__init__()\n",
        "        self.sos_idx = sos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.device = device\n",
        "        self.embedding = nn.Embedding(n_tokens, embedding_dim, padding_idx).to(device)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True).to(device)\n",
        "        self.fc = nn.Linear(hidden_size, n_tokens).to(device)\n",
        "\n",
        "    def forward(self, X, h):\n",
        "        embedded = self.embedding(X).unsqueeze(1)\n",
        "        _, h_n = self.rnn(embedded, h)\n",
        "        output = self.fc(h_n)\n",
        "        return h_n, output\n",
        "\n",
        "    def generate(self, hidden, length=None, constraint_mode=True, target=None, train=False):\n",
        "        index = 0\n",
        "        batch_size = hidden.size(1)\n",
        "        eos_cpt = 0\n",
        "        logits = []\n",
        "\n",
        "        input = torch.LongTensor([self.sos_idx]).repeat(batch_size).to(self.device)\n",
        "        while index != length:\n",
        "            hidden, output = self.forward(input, hidden)\n",
        "            logits.append(output)\n",
        "            if not constraint_mode:\n",
        "                input = torch.softmax(output, dim=-1).argmax(dim=-1)[0]\n",
        "                if input.size(0) > 1: input = input.squeeze()\n",
        "            else:\n",
        "                input = target[:, index]\n",
        "            eos_cpt += torch.sum(input == self.eos_idx).item()\n",
        "            if not train and eos_cpt == batch_size:\n",
        "                break\n",
        "            index += 1\n",
        "\n",
        "        return torch.cat(logits, dim=0).transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ciptSgBD3I8w"
      },
      "outputs": [],
      "source": [
        "class TraductionModel(nn.Module):\n",
        "    def __init__(self, source_vocab, dest_vocab, encoder_embedding_dim, decoder_embedding_dim,\n",
        "                hidden_size, padding_idx=0, device=torch.device(\"cpu\")):\n",
        "        super().__init__()\n",
        "        self.source_vocab = source_vocab\n",
        "        self.dest_vocab = dest_vocab\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(len(source_vocab), encoder_embedding_dim, hidden_size, padding_idx, device=device)\n",
        "        self.decoder = Decoder(len(dest_vocab), decoder_embedding_dim, hidden_size, padding_idx,\n",
        "                            sos_idx=dest_vocab.SOS, eos_idx=dest_vocab.EOS, device=device)\n",
        "\n",
        "    def forward(self, source, target, max_length, constraint_mode=True, train=True):\n",
        "        source_h_n = self.encoder(source)\n",
        "        if train: max_length = target.size(1)\n",
        "        logits = self.decoder.generate(source_h_n, max_length, constraint_mode, target, train)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, source_text, max_length=20):\n",
        "        source_text = normalize(source_text)\n",
        "        source = torch.tensor(\n",
        "                    [self.source_vocab.get(o) for o in source_text.split(\" \")] +\n",
        "                    [self.source_vocab.EOS]\n",
        "                ).unsqueeze(0).to(self.device)\n",
        "        logits = self.forward(source, target=None, max_length=max_length, constraint_mode=False, train=False)\n",
        "        predicts = logits.argmax(-1).squeeze()\n",
        "        target_text = self.dest_vocab.getwords(predicts.tolist())\n",
        "        return ' '.join(target_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N2-B7vc33I8x"
      },
      "outputs": [],
      "source": [
        "def train_step(model, optimizer, loss_fn, dataloader, constraint_mode=True, device=torch.device(\"cpu\")):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for (source, _, target, _) in dataloader:\n",
        "        source, target = source.T.to(device), target.T.to(device)\n",
        "        logits = model(source, target, max_length=target.size(1), constraint_mode=constraint_mode, train=True)\n",
        "        logits, target = logits.flatten(end_dim=1), target.flatten()\n",
        "        loss = loss_fn(logits, target)\n",
        "        total_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yx2ImXTc3I8x"
      },
      "outputs": [],
      "source": [
        "def validate(model, loss_fn, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for (source, _, target, _) in dataloader:\n",
        "            source, target = source.T.to(device), target.T.to(device)\n",
        "            logits = model(source, target, max_length=target.size(1), constraint_mode=False, train=True)\n",
        "            logits, target = logits.flatten(end_dim=1), target.flatten()\n",
        "            loss = loss_fn(logits, target)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bkkc2FX13I8x"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "        model,\n",
        "        optimizer,\n",
        "        device,\n",
        "        loss_fn,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        writer,\n",
        "        n_epochs=20,\n",
        "    ):\n",
        "    for epoch in tqdm(range(1, n_epochs+1), \"Training\"):\n",
        "        constraint_mode_probability = (n_epochs-epoch-1) / n_epochs\n",
        "        constraint_mode = (random.random() <= constraint_mode_probability)\n",
        "        train_loss = train_step(model, optimizer, loss_fn, train_loader, constraint_mode, device)\n",
        "        test_loss = validate(model, loss_fn, test_loader, device)\n",
        "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "        writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
        "        if epoch % (n_epochs // 10) == 0:\n",
        "            print(f\"[Epoch {epoch}] train : loss = {train_loss:.2f}, test : loss = {test_loss:.2f}\")\n",
        "            print(f\"Traduction 'she loves me' : {model.predict('she loves me.')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXALdLTe3I8y",
        "outputId": "9f2fe68e-63fe-478b-f2e9-3831a91d19bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 136521/136521 [00:11<00:00, 11517.73it/s]\n",
            "100%|██████████| 34132/34132 [00:01<00:00, 17700.91it/s]\n"
          ]
        }
      ],
      "source": [
        "BASE_PATH = \"./\"\n",
        "FILE = BASE_PATH + \"en-fra.txt\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(FILE) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
        "idxTrain = int(0.8*len(lines))\n",
        "\n",
        "vocEng = Vocabulary(True)\n",
        "vocFra = Vocabulary(True)\n",
        "MAX_LEN=20\n",
        "BATCH_SIZE=16\n",
        "\n",
        "datatrain = TradDataset(\"\".join(lines[:idxTrain]),vocEng,vocFra,max_len=MAX_LEN)\n",
        "datatest = TradDataset(\"\".join(lines[idxTrain:]),vocEng,vocFra,max_len=MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(datatrain, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(datatest, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "S_EMBEDDING_DIM=40\n",
        "T_EMBEDDING_DIM=40\n",
        "HIDDEN_SIZE=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnS-_zxY3I8y",
        "outputId": "6eef5722-e75b-491f-e06d-47e39d493213"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 10/100 [03:48<33:22, 22.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] train : loss = 6586.91, test : loss = 1816.93\n",
            "Traduction 'she loves me' : elle est ma mon EOS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 13/100 [04:52<31:20, 21.62s/it]"
          ]
        }
      ],
      "source": [
        "model = TraductionModel(\n",
        "    source_vocab=vocEng,\n",
        "    dest_vocab=vocFra,\n",
        "    encoder_embedding_dim=S_EMBEDDING_DIM,\n",
        "    decoder_embedding_dim=T_EMBEDDING_DIM,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    padding_idx=Vocabulary.PAD,\n",
        "    device=device\n",
        ").to(device)\n",
        "\n",
        "LR=1e-2\n",
        "N_EPOCHS=100\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=Vocabulary.PAD)\n",
        "writer = SummaryWriter(BASE_PATH + \"runs/traduction/\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\"))\n",
        "\n",
        "train(model, optimizer, device, loss_fn, train_loader, test_loader, writer, N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYtajv2Wu96h"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"I don't have a key.\",\n",
        "    \"She gets up early.\",\n",
        "    \"I'm in fair shape.\",\n",
        "    \"Everyone got sick.\",\n",
        "    \"You're all alone.\",\n",
        "    \"Tom isn't my son.\",\n",
        "    \"Feed the hamster.\",\n",
        "    \"Who did he see?\"\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(f\"{sentence} => {model.predict(sentence)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
