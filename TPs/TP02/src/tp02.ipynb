{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Advanced Machine Learning and Deep Learning (Master DAC)</h1>\n",
    "<h2>TP 02 : Graphe de calcul, autograd et modules</h2>\n",
    "\n",
    "<hr>\n",
    "<strong>Ben Kabongo</strong>, M2 MVA <br>\n",
    "ben.kabongo_buzangu@ens.paris-saclay.fr <br>\n",
    "<i>Novembre 2023</i>\n",
    "<hr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "## Installer datamaestro et datamaestro-ml pip install datamaestro datamaestro-ml\n",
    "import datamaestro\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datamaestro.prepare_dataset(\"edu.uci.boston\")\n",
    "colnames, datax, datay = data.data()\n",
    "datax = torch.tensor(datax,dtype=torch.float)\n",
    "datay = torch.tensor(datay,dtype=torch.float).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémenter un algorithme de descente du gradient batch pour la régression linéaire en utilisant les fonctionnalités de la différenciation automatique. Utiliser votre code du TME 1 (en utilisant ou non vos propres fonctions), supprimer le contexte et utiliser la différenciation automatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGD_linear_regression(X, y, eps=1e-4, max_iter=10):\n",
    "    linear = nn.Linear(X.size(1), 1)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        pred = linear(X)\n",
    "        loss = mse(pred, y)\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss, i)\n",
    "        print(f\"Epoch {i}: loss {loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            linear.weight -= eps * linear.weight.grad\n",
    "            linear.bias -= eps * linear.bias.grad\n",
    "\n",
    "        linear.weight.grad.zero_()\n",
    "        linear.bias.grad.zero_()\n",
    "\n",
    "    return linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester votre implémentation avec les données de Boston Housing. Tracer la courbe du coût en apprentissage et celle en test. Utiliser pour cela de préférence `tensorboard`. Utilisez pour l’instant seulement la fonction `add_scalar` après avoir créé un fichier de log grâce à la commande `SummaryWriter(path)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 564.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 7240.02490234375\n",
      "Epoch 1: loss 1184.814208984375\n",
      "Epoch 2: loss 332.5049133300781\n",
      "Epoch 3: loss 208.3081512451172\n",
      "Epoch 4: loss 186.38661193847656\n",
      "Epoch 5: loss 179.1766815185547\n",
      "Epoch 6: loss 174.395263671875\n",
      "Epoch 7: loss 170.29058837890625\n",
      "Epoch 8: loss 166.5868377685547\n",
      "Epoch 9: loss 163.21731567382812\n",
      "Epoch 10: loss 160.14727783203125\n",
      "Epoch 11: loss 157.34866333007812\n",
      "Epoch 12: loss 154.7965545654297\n",
      "Epoch 13: loss 152.46839904785156\n",
      "Epoch 14: loss 150.3436279296875\n",
      "Epoch 15: loss 148.4036865234375\n",
      "Epoch 16: loss 146.63162231445312\n",
      "Epoch 17: loss 145.0120849609375\n",
      "Epoch 18: loss 143.53109741210938\n",
      "Epoch 19: loss 142.1759796142578\n",
      "Epoch 20: loss 140.93524169921875\n",
      "Epoch 21: loss 139.7984161376953\n",
      "Epoch 22: loss 138.7560272216797\n",
      "Epoch 23: loss 137.79940795898438\n",
      "Epoch 24: loss 136.9207000732422\n",
      "Epoch 25: loss 136.1128387451172\n",
      "Epoch 26: loss 135.36932373046875\n",
      "Epoch 27: loss 134.6842803955078\n",
      "Epoch 28: loss 134.0523681640625\n",
      "Epoch 29: loss 133.46878051757812\n",
      "Epoch 30: loss 132.92904663085938\n",
      "Epoch 31: loss 132.42922973632812\n",
      "Epoch 32: loss 131.9656524658203\n",
      "Epoch 33: loss 131.53504943847656\n",
      "Epoch 34: loss 131.13438415527344\n",
      "Epoch 35: loss 130.760986328125\n",
      "Epoch 36: loss 130.41232299804688\n",
      "Epoch 37: loss 130.08619689941406\n",
      "Epoch 38: loss 129.78053283691406\n",
      "Epoch 39: loss 129.49349975585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/\", comment=\"batch\")\n",
    "_ = BGD_linear_regression(datax, datay, eps=1e-6, max_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémenter une descente de gradient stochastique et une mini-batch. Comparer la vitesse de convergence et les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_linear_regression(X, y, eps=1e-4, max_iter=10):\n",
    "    linear = nn.Linear(X.size(1), 1)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for j in range(X.size(0)):\n",
    "            index = torch.randint(0, X.size(0), (1,))\n",
    "            sample_X = X[index]\n",
    "            sample_y = y[index]\n",
    "\n",
    "            pred = linear(sample_X)\n",
    "            loss = mse(pred, sample_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                linear.weight -= eps * linear.weight.grad\n",
    "                linear.bias -= eps * linear.bias.grad\n",
    "\n",
    "            linear.weight.grad.zero_()\n",
    "            linear.bias.grad.zero_()\n",
    "\n",
    "        avg_loss = total_loss / X.size(0)\n",
    "\n",
    "        writer.add_scalar('Loss/train', avg_loss, i)\n",
    "        print(f\"Epoch {i}: average loss {avg_loss}\")\n",
    "\n",
    "    return linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss 152.14925797648863\n",
      "Epoch 1: average loss 89.62942103107079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:00<00:01, 34.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: average loss 94.21605929816229\n",
      "Epoch 3: average loss 99.08319909891031\n",
      "Epoch 4: average loss 100.00253381442921\n",
      "Epoch 5: average loss 96.16227481286043\n",
      "Epoch 6: average loss 100.89375995898726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [00:00<00:00, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: average loss 121.02738563370087\n",
      "Epoch 8: average loss 89.77554371136308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [00:00<00:00, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: average loss 107.62542786611071\n",
      "Epoch 10: average loss 83.0144473517292\n",
      "Epoch 11: average loss 89.39328234382087\n",
      "Epoch 12: average loss 86.42862208271337\n",
      "Epoch 13: average loss 95.69864511758308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [00:00<00:00, 34.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: average loss 92.04644870265408\n",
      "Epoch 15: average loss 87.5682984004897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [00:00<00:00, 34.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: average loss 97.46834600978579\n",
      "Epoch 17: average loss 86.31503307857356\n",
      "Epoch 18: average loss 86.8840832363781\n",
      "Epoch 19: average loss 78.28739411942787\n",
      "Epoch 20: average loss 97.98470614814033\n",
      "Epoch 21: average loss 87.1894566345027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:00<00:00, 34.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: average loss 89.10090888954429\n",
      "Epoch 23: average loss 95.55881452540679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:00<00:00, 34.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: average loss 75.01043305948248\n",
      "Epoch 25: average loss 82.33257305602582\n",
      "Epoch 26: average loss 87.7139450124679\n",
      "Epoch 27: average loss 91.71854599604552\n",
      "Epoch 28: average loss 86.42235369863268\n",
      "Epoch 29: average loss 85.26041293510912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [00:00<00:00, 34.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: average loss 75.4639505542369\n",
      "Epoch 31: average loss 88.61876963019158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [00:01<00:00, 34.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: average loss 86.42623379142525\n",
      "Epoch 33: average loss 71.73236917125149\n",
      "Epoch 34: average loss 84.91854294615968\n",
      "Epoch 35: average loss 84.88251330639376\n",
      "Epoch 36: average loss 68.33994150601899\n",
      "Epoch 37: average loss 70.88424099094419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 34.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: average loss 83.02520347198494\n",
      "Epoch 39: average loss 80.9326351682661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/\", comment=\"stochastic\")\n",
    "_ = SGD_linear_regression(datax, datay, eps=1e-6, max_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatch_linear_regression(X, y, eps=1e-4, batch_size=32, max_iter=10):\n",
    "    linear = nn.Linear(X.size(1), 1)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for j in range(0, X.size(0), batch_size):\n",
    "            batch_X = X[j:j+batch_size]\n",
    "            batch_y = y[j:j+batch_size]\n",
    "\n",
    "            pred = linear(batch_X)\n",
    "            loss = mse(pred, batch_y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                linear.weight -= eps * linear.weight.grad\n",
    "                linear.bias -= eps * linear.bias.grad\n",
    "\n",
    "            linear.weight.grad.zero_()\n",
    "            linear.bias.grad.zero_()\n",
    "\n",
    "        avg_loss = total_loss / (X.size(0) / batch_size)\n",
    "\n",
    "        writer.add_scalar('Loss/train', avg_loss, i)\n",
    "        print(f\"Epoch {i}: average loss {avg_loss}\")\n",
    "\n",
    "    return linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1070.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss 760.9731768581707\n",
      "Epoch 1: average loss 229.24980965716094\n",
      "Epoch 2: average loss 160.1992240574049\n",
      "Epoch 3: average loss 130.64296701303113\n",
      "Epoch 4: average loss 118.20572152722023\n",
      "Epoch 5: average loss 113.04170582888155\n",
      "Epoch 6: average loss 110.86841170118731\n",
      "Epoch 7: average loss 109.8572376839257\n",
      "Epoch 8: average loss 109.25089671018095\n",
      "Epoch 9: average loss 108.75226891559103\n",
      "Epoch 10: average loss 108.25663389424561\n",
      "Epoch 11: average loss 107.73615334250711\n",
      "Epoch 12: average loss 107.19094016335227\n",
      "Epoch 13: average loss 106.62941045346467\n",
      "Epoch 14: average loss 106.06074131901556\n",
      "Epoch 15: average loss 105.49255576152575\n",
      "Epoch 16: average loss 104.93043536159831\n",
      "Epoch 17: average loss 104.378173828125\n",
      "Epoch 18: average loss 103.83824887483016\n",
      "Epoch 19: average loss 103.312098325948\n",
      "Epoch 20: average loss 102.80051394979002\n",
      "Epoch 21: average loss 102.30378150186048\n",
      "Epoch 22: average loss 101.82188783427002\n",
      "Epoch 23: average loss 101.354594475667\n",
      "Epoch 24: average loss 100.90159516466466\n",
      "Epoch 25: average loss 100.4624321375911\n",
      "Epoch 26: average loss 100.03667151409647\n",
      "Epoch 27: average loss 99.62380185334578\n",
      "Epoch 28: average loss 99.2233343915977\n",
      "Epoch 29: average loss 98.83479833791378\n",
      "Epoch 30: average loss 98.45771313090569\n",
      "Epoch 31: average loss 98.09160834150352\n",
      "Epoch 32: average loss 97.73602644728106\n",
      "Epoch 33: average loss 97.39055612435925\n",
      "Epoch 34: average loss 97.05476578422214\n",
      "Epoch 35: average loss 96.72827498243731\n",
      "Epoch 36: average loss 96.41069157415698\n",
      "Epoch 37: average loss 96.10167395550272\n",
      "Epoch 38: average loss 95.80084156141922\n",
      "Epoch 39: average loss 95.50790055467206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/\", comment=\"mini-batch\")\n",
    "_ = MiniBatch_linear_regression(datax, datay, eps=1e-6, batch_size=32, max_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser les modules `torch.nn.Linear`, `torch.nn.Tanh` et `torch.nn.MSELoss` pour implémenter un réseau à deux couches : `lineaire → tanh → lineaire → MSE`. Implémenter la boucle de descente de gradient avec l’optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optim_GD_linear_regression(X, y, eps=1e-4, max_iter=10, hidden_dim=10):\n",
    "    linear_1 = nn.Linear(X.size(1), hidden_dim)\n",
    "    linear_2 = nn.Linear(hidden_dim, 1)\n",
    "    tanh = nn.Tanh()\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(params=[*linear_1.parameters(), *linear_2.parameters()], lr=eps)\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        output = linear_1(X)\n",
    "        output = tanh(output)\n",
    "        pred = linear_2(output)\n",
    "        loss = mse(pred, y)\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss, i)\n",
    "        print(f\"Epoch {i}: loss {loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return [linear_1, linear_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 4253.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 621.6826782226562\n",
      "Epoch 1: loss 452.42254638671875\n",
      "Epoch 2: loss 309.60089111328125\n",
      "Epoch 3: loss 221.37013244628906\n",
      "Epoch 4: loss 167.0432891845703\n",
      "Epoch 5: loss 134.68777465820312\n",
      "Epoch 6: loss 115.00262451171875\n",
      "Epoch 7: loss 103.02374267578125\n",
      "Epoch 8: loss 93.6973648071289\n",
      "Epoch 9: loss 132.7603759765625\n",
      "Epoch 10: loss 113.83011627197266\n",
      "Epoch 11: loss 102.31292724609375\n",
      "Epoch 12: loss 95.3058853149414\n",
      "Epoch 13: loss 91.04280090332031\n",
      "Epoch 14: loss 88.44915771484375\n",
      "Epoch 15: loss 86.87117004394531\n",
      "Epoch 16: loss 85.9111099243164\n",
      "Epoch 17: loss 85.32701110839844\n",
      "Epoch 18: loss 84.9716567993164\n",
      "Epoch 19: loss 84.75545501708984\n",
      "Epoch 20: loss 84.62391662597656\n",
      "Epoch 21: loss 84.54388427734375\n",
      "Epoch 22: loss 84.49520874023438\n",
      "Epoch 23: loss 84.465576171875\n",
      "Epoch 24: loss 84.44755554199219\n",
      "Epoch 25: loss 84.43659973144531\n",
      "Epoch 26: loss 84.42992401123047\n",
      "Epoch 27: loss 84.42586517333984\n",
      "Epoch 28: loss 84.42340087890625\n",
      "Epoch 29: loss 84.4218978881836\n",
      "Epoch 30: loss 84.42097473144531\n",
      "Epoch 31: loss 84.42042541503906\n",
      "Epoch 32: loss 84.42008972167969\n",
      "Epoch 33: loss 84.41987609863281\n",
      "Epoch 34: loss 84.41976165771484\n",
      "Epoch 35: loss 84.41968536376953\n",
      "Epoch 36: loss 84.41963958740234\n",
      "Epoch 37: loss 84.41960144042969\n",
      "Epoch 38: loss 84.41958618164062\n",
      "Epoch 39: loss 84.41957092285156\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/\", comment=\"optim\")\n",
    "_ = Optim_GD_linear_regression(datax, datay, eps=1e-2, max_iter=40, hidden_dim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser maintenant un conteneur - par exemple le module `torch.nn.Sequential` - pour implémenter le même réseau. Parcourer la doc pour comprendre la différence entre les différents types de conteneurs. Que se passe-t-il pour les paramètres des modules mis ainsi ensemble ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequential_Optim_GD_linear_regression(X, y, eps=1e-4, max_iter=10, hidden_dim=10):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X.size(1), hidden_dim),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(hidden_dim, 1)\n",
    "    )\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=eps)\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        pred = model(X)\n",
    "        loss = mse(pred, y)\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss, i)\n",
    "        print(f\"Epoch {i}: loss {loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 3497.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 561.9471435546875\n",
      "Epoch 1: loss 404.00128173828125\n",
      "Epoch 2: loss 280.6111145019531\n",
      "Epoch 3: loss 203.78248596191406\n",
      "Epoch 4: loss 157.04000854492188\n",
      "Epoch 5: loss 128.601806640625\n",
      "Epoch 6: loss 111.30004119873047\n",
      "Epoch 7: loss 100.77365112304688\n",
      "Epoch 8: loss 94.36937713623047\n",
      "Epoch 9: loss 90.47303771972656\n",
      "Epoch 10: loss 88.10249328613281\n",
      "Epoch 11: loss 86.66024780273438\n",
      "Epoch 12: loss 85.78279113769531\n",
      "Epoch 13: loss 85.24895477294922\n",
      "Epoch 14: loss 84.92416381835938\n",
      "Epoch 15: loss 84.72655487060547\n",
      "Epoch 16: loss 84.60633087158203\n",
      "Epoch 17: loss 84.53319549560547\n",
      "Epoch 18: loss 84.48869323730469\n",
      "Epoch 19: loss 84.46162414550781\n",
      "Epoch 20: loss 84.44514465332031\n",
      "Epoch 21: loss 84.43513488769531\n",
      "Epoch 22: loss 84.42902374267578\n",
      "Epoch 23: loss 84.4253158569336\n",
      "Epoch 24: loss 84.4230728149414\n",
      "Epoch 25: loss 84.42169189453125\n",
      "Epoch 26: loss 84.42085266113281\n",
      "Epoch 27: loss 84.42034912109375\n",
      "Epoch 28: loss 84.42003631591797\n",
      "Epoch 29: loss 84.41985321044922\n",
      "Epoch 30: loss 84.41973876953125\n",
      "Epoch 31: loss 84.41966247558594\n",
      "Epoch 32: loss 84.41961669921875\n",
      "Epoch 33: loss 84.41960144042969\n",
      "Epoch 34: loss 84.41957092285156\n",
      "Epoch 35: loss 84.41957092285156\n",
      "Epoch 36: loss 84.41956329345703\n",
      "Epoch 37: loss 84.4195556640625\n",
      "Epoch 38: loss 84.41956329345703\n",
      "Epoch 39: loss 84.4195556640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/\", comment=\"sequential\")\n",
    "_ = Optim_GD_linear_regression(datax, datay, eps=1e-2, max_iter=40, hidden_dim=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
